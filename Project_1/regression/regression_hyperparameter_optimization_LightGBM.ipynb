{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e9a2f481",
   "metadata": {},
   "source": [
    "####  Finding optimal hyperparameters for one of the algorithms (LightGBM in this case)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d1599622",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import mean_absolute_error, mean_squared_error, r2_score\n",
    "from sklearn.preprocessing import StandardScaler, MinMaxScaler\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.svm import SVR\n",
    "from sklearn.neighbors import KNeighborsRegressor\n",
    "\n",
    "import seaborn as sns\n",
    "import xgboost as xgb\n",
    "import lightgbm as lgb\n",
    "import catboost as cb\n",
    "\n",
    "import tensorflow as tf\n",
    "import keras\n",
    "from keras import layers"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "01ebb264",
   "metadata": {},
   "source": [
    "#### Load the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "1716cbb2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>housing_median_age</th>\n",
       "      <th>total_rooms</th>\n",
       "      <th>population</th>\n",
       "      <th>median_income</th>\n",
       "      <th>median_house_value</th>\n",
       "      <th>distance_to_nearest_city</th>\n",
       "      <th>ocean_proximity_&lt;1H OCEAN</th>\n",
       "      <th>ocean_proximity_INLAND</th>\n",
       "      <th>ocean_proximity_ISLAND</th>\n",
       "      <th>ocean_proximity_NEAR BAY</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>41.0</td>\n",
       "      <td>880.0</td>\n",
       "      <td>322.0</td>\n",
       "      <td>8.3252</td>\n",
       "      <td>452600.0</td>\n",
       "      <td>20.33</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>21.0</td>\n",
       "      <td>7099.0</td>\n",
       "      <td>2401.0</td>\n",
       "      <td>8.3014</td>\n",
       "      <td>358500.0</td>\n",
       "      <td>19.91</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>52.0</td>\n",
       "      <td>1467.0</td>\n",
       "      <td>496.0</td>\n",
       "      <td>7.2574</td>\n",
       "      <td>352100.0</td>\n",
       "      <td>17.84</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>52.0</td>\n",
       "      <td>1274.0</td>\n",
       "      <td>558.0</td>\n",
       "      <td>5.6431</td>\n",
       "      <td>341300.0</td>\n",
       "      <td>17.06</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>52.0</td>\n",
       "      <td>1627.0</td>\n",
       "      <td>565.0</td>\n",
       "      <td>3.8462</td>\n",
       "      <td>342200.0</td>\n",
       "      <td>17.06</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   housing_median_age  total_rooms  population  median_income  \\\n",
       "0                41.0        880.0       322.0         8.3252   \n",
       "1                21.0       7099.0      2401.0         8.3014   \n",
       "2                52.0       1467.0       496.0         7.2574   \n",
       "3                52.0       1274.0       558.0         5.6431   \n",
       "4                52.0       1627.0       565.0         3.8462   \n",
       "\n",
       "   median_house_value  distance_to_nearest_city  ocean_proximity_<1H OCEAN  \\\n",
       "0            452600.0                     20.33                          0   \n",
       "1            358500.0                     19.91                          0   \n",
       "2            352100.0                     17.84                          0   \n",
       "3            341300.0                     17.06                          0   \n",
       "4            342200.0                     17.06                          0   \n",
       "\n",
       "   ocean_proximity_INLAND  ocean_proximity_ISLAND  ocean_proximity_NEAR BAY  \n",
       "0                       0                       0                         1  \n",
       "1                       0                       0                         1  \n",
       "2                       0                       0                         1  \n",
       "3                       0                       0                         1  \n",
       "4                       0                       0                         1  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv(\"housing_before_optimization.csv\")\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "25839252",
   "metadata": {},
   "source": [
    "####  Same X/y + train/test split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "7a2ceeff",
   "metadata": {},
   "outputs": [],
   "source": [
    "categorical_variables = [ \n",
    "    \"ocean_proximity_<1H OCEAN\",\n",
    "    \"ocean_proximity_INLAND\",\n",
    "    \"ocean_proximity_ISLAND\",\n",
    "    \"ocean_proximity_NEAR BAY\"]\n",
    "\n",
    "# continuous variables also into a list\n",
    "continuous_variables = [ \n",
    "    \"housing_median_age\",\n",
    "    \"total_rooms\",\n",
    "    \"population\",\n",
    "    \"median_income\",\n",
    "    \"distance_to_nearest_city\",\n",
    "    \"median_house_value\"]\n",
    "\n",
    "# the usual X/y -split\n",
    "X = df.drop(\"median_house_value\", axis=1)\n",
    "y = df['median_house_value']\n",
    "\n",
    "# usual train/test -split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2)\n",
    "\n",
    "# NOTE! SCALING => some of the algorithms require this\n",
    "scaler = StandardScaler()\n",
    "\n",
    "# create separate versions for the scaled data\n",
    "# because we need both unscaled and scaled versions later\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_test_scaled = scaler.transform(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f4886870",
   "metadata": {},
   "source": [
    "####  In this example, use RandomizedSearchCV to search better hyperparameters for our algorithm -  LightGBM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "da52c1ec",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 300 candidates, totalling 900 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Storage\\Studies\\Lapland_AMK\\6_semester\\Advanced_ML\\venv12\\Lib\\site-packages\\numpy\\ma\\core.py:2885: RuntimeWarning: invalid value encountered in cast\n",
      "  _data = np.array(data, dtype=dtype, copy=copy,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000219 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 1079\n",
      "[LightGBM] [Info] Number of data points in the train set: 15580, number of used features: 8\n",
      "[LightGBM] [Info] Start training from score 192477.721181\n",
      "\n",
      "Best parameters from RandomizedSearchCV: {'learning_rate': np.float64(0.13120689655172416), 'max_depth': 23, 'num_leaves': 46}\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "import numpy as np\n",
    "from scipy.stats import randint\n",
    "\n",
    "# Define the parameter distributions with integer ranges\n",
    "# Notice how we use NumPy and scipy in order to have ranges of values\n",
    "# for the RandomizedSearch, which it tries to combine in a random manner \n",
    "# => based on luck, you might stumble upon a very good combination of parameters\n",
    "param_dist = {\n",
    "    'learning_rate': np.linspace(0.08, 0.135, 30), \n",
    "    'num_leaves': randint(25, 51),  \n",
    "    'max_depth': randint(-1, 30), \n",
    "}\n",
    "\n",
    "# Setup RandomizedSearchCV\n",
    "# search 300 times (n_iter)\n",
    "# n_jobs => -1 => use all CPU cores\n",
    "# cv = cross-validation strategy (higher is often better, but takes more time), typical values 3-5\n",
    "random_search = RandomizedSearchCV(\n",
    "    estimator=lgb.LGBMRegressor(), \n",
    "    param_distributions=param_dist, \n",
    "    n_iter=300,  # Number of random combinations to test\n",
    "    cv=3,\n",
    "    n_jobs=-1,\n",
    "    verbose=1,  \n",
    "    scoring='neg_mean_squared_error'\n",
    ")\n",
    "\n",
    "# Fit the randomized search\n",
    "random_search.fit(X_train, y_train)\n",
    "\n",
    "# Get the best parameters\n",
    "best_params_random = random_search.best_params_\n",
    "print(\"\\nBest parameters from RandomizedSearchCV:\", best_params_random)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "e5718485",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-1594676715.389762 -2688690636.762296\n"
     ]
    }
   ],
   "source": [
    "# Taken from AI to understand if the model is overfitting or not. According to AI if train > test â†’ overfitting and i need to reduce max_depth\n",
    "# If train and test are about the same than i am good. \n",
    "# In my case -df without dropping rows that are higher than 500 001 -  train_score-1900641404.2566435, test_score-2604742485.6073427) i am good with these parameters, because test is not not wildly higher than train.\n",
    "# PS1 - using df before optimization, i got train_score = -1968491890.4575675 and test_score = -2972746424.5103645. According to Ai, \n",
    "# I need to  change max_depth from 'max_depth': randint(-1, 40) to \"max_depth\": randint(4, 10) for example.\n",
    "# PS2 - df before optimization, train_score = -2191108649.1476135 and test_score = -3034239139.642399. A bit better but still quite a big gap.\n",
    "\n",
    "train_score = random_search.score(X_train, y_train)\n",
    "test_score  = random_search.score(X_test, y_test)\n",
    "\n",
    "print(train_score, test_score)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv12 (3.12.10)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
