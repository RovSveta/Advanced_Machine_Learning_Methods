{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e9a2f481",
   "metadata": {},
   "source": [
    "####  Finding optimal hyperparameters for one of the algorithms (LightGBM in this case)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d1599622",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import mean_absolute_error, mean_squared_error, r2_score\n",
    "from sklearn.preprocessing import StandardScaler, MinMaxScaler\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.svm import SVR\n",
    "from sklearn.neighbors import KNeighborsRegressor\n",
    "\n",
    "import seaborn as sns\n",
    "import xgboost as xgb\n",
    "import lightgbm as lgb\n",
    "import catboost as cb\n",
    "\n",
    "import tensorflow as tf\n",
    "import keras\n",
    "from keras import layers"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "01ebb264",
   "metadata": {},
   "source": [
    "#### Load the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1716cbb2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>housing_median_age</th>\n",
       "      <th>total_rooms</th>\n",
       "      <th>population</th>\n",
       "      <th>median_income</th>\n",
       "      <th>median_house_value</th>\n",
       "      <th>distance_to_nearest_city</th>\n",
       "      <th>ocean_proximity_&lt;1H OCEAN</th>\n",
       "      <th>ocean_proximity_INLAND</th>\n",
       "      <th>ocean_proximity_ISLAND</th>\n",
       "      <th>ocean_proximity_NEAR BAY</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>52.0</td>\n",
       "      <td>1627.0</td>\n",
       "      <td>565.0</td>\n",
       "      <td>3.8462</td>\n",
       "      <td>342200.0</td>\n",
       "      <td>17.06</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>52.0</td>\n",
       "      <td>919.0</td>\n",
       "      <td>413.0</td>\n",
       "      <td>4.0368</td>\n",
       "      <td>269700.0</td>\n",
       "      <td>17.06</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>52.0</td>\n",
       "      <td>2535.0</td>\n",
       "      <td>1094.0</td>\n",
       "      <td>3.6591</td>\n",
       "      <td>299200.0</td>\n",
       "      <td>16.55</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>52.0</td>\n",
       "      <td>3104.0</td>\n",
       "      <td>1157.0</td>\n",
       "      <td>3.1200</td>\n",
       "      <td>241400.0</td>\n",
       "      <td>16.55</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>42.0</td>\n",
       "      <td>2555.0</td>\n",
       "      <td>1206.0</td>\n",
       "      <td>2.0804</td>\n",
       "      <td>226700.0</td>\n",
       "      <td>15.76</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   housing_median_age  total_rooms  population  median_income  \\\n",
       "0                52.0       1627.0       565.0         3.8462   \n",
       "1                52.0        919.0       413.0         4.0368   \n",
       "2                52.0       2535.0      1094.0         3.6591   \n",
       "3                52.0       3104.0      1157.0         3.1200   \n",
       "4                42.0       2555.0      1206.0         2.0804   \n",
       "\n",
       "   median_house_value  distance_to_nearest_city  ocean_proximity_<1H OCEAN  \\\n",
       "0            342200.0                     17.06                          0   \n",
       "1            269700.0                     17.06                          0   \n",
       "2            299200.0                     16.55                          0   \n",
       "3            241400.0                     16.55                          0   \n",
       "4            226700.0                     15.76                          0   \n",
       "\n",
       "   ocean_proximity_INLAND  ocean_proximity_ISLAND  ocean_proximity_NEAR BAY  \n",
       "0                       0                       0                         1  \n",
       "1                       0                       0                         1  \n",
       "2                       0                       0                         1  \n",
       "3                       0                       0                         1  \n",
       "4                       0                       0                         1  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv(\"processed_regression_housing.csv\")\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "25839252",
   "metadata": {},
   "source": [
    "####  Same X/y + train/test split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a2ceeff",
   "metadata": {},
   "outputs": [],
   "source": [
    "categorical_variables = [ \n",
    "    \"ocean_proximity_<1H OCEAN\",\n",
    "    \"ocean_proximity_INLAND\",\n",
    "    \"ocean_proximity_ISLAND\",\n",
    "    \"ocean_proximity_NEAR BAY\"]\n",
    "\n",
    "# continuous variables also into a list\n",
    "continuous_variables = [ \n",
    "    \"housing_median_age\",\n",
    "    \"total_rooms\",\n",
    "    \"population\",\n",
    "    \"median_income\",\n",
    "    \"distance_to_nearest_city\",\n",
    "    \"median_house_value\"]\n",
    "\n",
    "# the usual X/y -split\n",
    "X = df.drop(\"median_house_value\", axis=1)\n",
    "y = df['median_house_value']\n",
    "\n",
    "# usual train/test -split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2)\n",
    "\n",
    "# NOTE! SCALING => some of the algorithms require this\n",
    "scaler = StandardScaler()\n",
    "\n",
    "# create separate versions for the scaled data\n",
    "# because we need both unscaled and scaled versions later\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_test_scaled = scaler.transform(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f4886870",
   "metadata": {},
   "source": [
    "####  In this example, use RandomizedSearchCV to search better hyperparameters for our algorithm -  CatBoost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da52c1ec",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 300 candidates, totalling 900 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Storage\\Studies\\Lapland_AMK\\6_semester\\Advanced_ML\\venv12\\Lib\\site-packages\\numpy\\ma\\core.py:2885: RuntimeWarning: invalid value encountered in cast\n",
      "  _data = np.array(data, dtype=dtype, copy=copy,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000264 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 1079\n",
      "[LightGBM] [Info] Number of data points in the train set: 14157, number of used features: 8\n",
      "[LightGBM] [Info] Start training from score 182489.022886\n",
      "\n",
      "Best parameters from RandomizedSearchCV: {'learning_rate': np.float64(0.08948275862068966), 'max_depth': 17, 'num_leaves': 48}\n"
     ]
    }
   ],
   "source": [
    "from catboost import CatBoostRegressor\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "from scipy.stats import randint, uniform\n",
    "\n",
    "# Define parameter distributions for CatBoost\n",
    "param_dist = {\n",
    "    'depth': randint(4, 10),                 # tree depth\n",
    "    'learning_rate': uniform(0.03, 0.15),    # learning rate range\n",
    "    'iterations': randint(300, 1200),        # number of trees\n",
    "    'l2_leaf_reg': uniform(1, 9),             # L2 regularization\n",
    "}\n",
    "\n",
    "# Setup RandomizedSearchCV\n",
    "random_search_cat = RandomizedSearchCV(\n",
    "    estimator=CatBoostRegressor(\n",
    "        loss_function='RMSE',\n",
    "        verbose=0,\n",
    "        random_seed=42\n",
    "    ),\n",
    "    param_distributions=param_dist,\n",
    "    n_iter=100,          # CatBoost is slower → 100 is realistic\n",
    "    cv=3,\n",
    "    n_jobs=-1,\n",
    "    verbose=1,\n",
    "    scoring='neg_mean_squared_error'\n",
    ")\n",
    "\n",
    "# Fit search\n",
    "random_search_cat.fit(X_train, y_train)\n",
    "\n",
    "# Best parameters\n",
    "print(\"Best parameters:\", random_search_cat.best_params_)\n",
    "print(\"Best CV score (neg MSE):\", random_search_cat.best_score_)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e5718485",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-1576518424.471511 -2280088940.2887855\n"
     ]
    }
   ],
   "source": [
    "# Taken from AI to understand if the model is overfitting or not. According to AI if train > test → overfitting and i need to reduce max_depth\n",
    "# If train and test are about the same than i am good. \n",
    "# In my case -df without dropping rows that are higher than 500 001 -  train_score-1900641404.2566435, test_score-2604742485.6073427) i am good with these parameters, because test is not not wildly higher than train.\n",
    "# PS1 - using df before optimization, i got train_score = -1968491890.4575675 and test_score = -2972746424.5103645. According to Ai, \n",
    "# I need to  change max_depth from 'max_depth': randint(-1, 40) to \"max_depth\": randint(4, 10) for example.\n",
    "# PS2 - df before optimization, train_score = -2191108649.1476135 and test_score = -3034239139.642399. A bit better but still quite a big gap.\n",
    "\n",
    "train_score = random_search.score(X_train, y_train)\n",
    "test_score  = random_search.score(X_test, y_test)\n",
    "\n",
    "print(train_score, test_score)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv12 (3.12.10)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
